{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac475fe-1f14-43f2-8ba2-ec044274b6a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2 style=\"color:orange;font-weight:bold;font-family:arial\">Speech Emotion Recognition System</h2>\n",
    "<h3 style=\"color:blue;font-weight:bold;font-family:arial\">Group 1</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158280f-dcfa-4025-88b1-7aea65634b5d",
   "metadata": {},
   "source": [
    "##### Samruddhi Khairnar - kbtug20170@kbtcoe.org \n",
    "##### Avichal Sharma - avichalsharma2003@gmail.com\n",
    "##### Yash Rokade - rokadeyash34@gmail.com\n",
    "##### Araya Gupta - arayagupta28@gmail.com\n",
    "##### Priyanshu Bisht - bisht.priyanshu05@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1023fa0-94ef-4a72-a6ca-d9895b2a96ea",
   "metadata": {},
   "source": [
    "#### **Recording Audio, Saving into .wav file** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e34995-b662-4332-b139-7d0e3d0c78d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded voice.\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=pyaudio.paInt16,channels=2,rate=44100,\n",
    "                input=True,frames_per_buffer=1024)\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(44100 / 1024 * 2)): # Record for 2 seconds\n",
    "    data = stream.read(1024)\n",
    "    frames.append(data)\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(\"rec.wav\", 'wb')\n",
    "wf.setnchannels(2)\n",
    "wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "wf.setframerate(44100)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "\n",
    "print('Recorded voice.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577bc5be-866f-43f9-884a-653364805ec6",
   "metadata": {},
   "source": [
    "#### **Imports for Librosa - audio feature extraction library** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da46a06-4475-4ffe-a6f5-74b5dbaedb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.util, librosa.display\n",
    "import numpy as np\n",
    "import mir_eval\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio\n",
    "import cmath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb89cb8-6c89-428a-9263-15210092c281",
   "metadata": {},
   "source": [
    "#### **Extracting features of the .wav file and storing in a list** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50038311-dd46-4d72-bc9d-477c0c5a9cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9220657e-6f0d-43af-bbe0-a256cd045b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y,_ = librosa.load('rec.wav')\n",
    "sr = 22500\n",
    "\n",
    "y,_ = librosa.effects.trim(y)\n",
    "MFCC = librosa.feature.mfcc(y=y, sr=sr); MFCC = [np.mean(x) for x in MFCC]\n",
    "y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "y_harmonic, y_percussive = y_harmonic.mean(), y_percussive.mean()\n",
    "C = librosa.cqt(y); C_mean = [np.mean(x) for x in C]; C_mean = [complex(x).real for x in C_mean]\n",
    "chroma = librosa.feature.chroma_cqt(C=C, sr=sr); chroma_mean = [np.mean(x) for x in chroma]\n",
    "a, b = [],[]\n",
    "for j in range(len(chroma_mean)):\n",
    "    polar = cmath.polar(complex(chroma_mean[j])); a.append(polar[0]); b.append(polar[1])\n",
    "onset_envelope = librosa.onset.onset_strength(y=y, sr=sr); onsets = librosa.onset.onset_detect(onset_envelope=onset_envelope)\n",
    "onsets = onsets.shape[0]; tempo, beats = librosa.beat.beat_track(onset_envelope=onset_envelope)\n",
    "c_sync = librosa.util.sync(chroma, beats, aggregate=np.median); c_sync = [np.mean(x) for x in c_sync]\n",
    "c, d = [],[]\n",
    "for j in range(len(c_sync)):\n",
    "    polar = cmath.polar(complex(c_sync[j])); c.append(polar[0]); d.append(polar[1])\n",
    "spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr); spectral_bandwidth = spectral_bandwidth.mean()\n",
    "spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]; spectral_rolloff = spectral_rolloff.mean()\n",
    "spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr); spectral_centroids = spectral_centroids.mean()\n",
    "\n",
    "arr = np.hstack(([], MFCC, y_harmonic, y_percussive, C_mean, a, b, onsets, tempo, beats.shape[0], c,d, spectral_bandwidth, spectral_rolloff, spectral_centroids,1,0,0,0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ad0bb-5176-4aba-9665-b4a50c0ee68a",
   "metadata": {},
   "source": [
    "#### **Loading the trained model and predicting emotion of the .wav file** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e0bea3-8ec6-4b6b-a135-bdc15f36e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51aefb29-ba34-4201-a1eb-6b061c6dd867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n",
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "emotions = ['Angry', 'Disgust', 'Fear', 'Happy/Joy', 'Neutral', 'Sad']\n",
    "\n",
    "with open('speech_emotion_classifier.pkl','rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    pred = model.predict(arr.reshape((1,165)))\n",
    "    print(emotions[int(np.where( pred == pred.max() )[1])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
